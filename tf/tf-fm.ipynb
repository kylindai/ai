{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFM(object):\n",
    "    \"\"\"\n",
    "    Field-aware Factorization Machine\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        :param config: configuration of hyperparameters\n",
    "        type of dict\n",
    "        \"\"\"\n",
    "        # number of latent factors\n",
    "        self.k = config['k']\n",
    "        # num of fields\n",
    "        self.f = config['f']\n",
    "        # num of features\n",
    "        self.p = feature_length\n",
    "        self.lr = config['lr']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.reg_l1 = config['reg_l1']\n",
    "        self.reg_l2 = config['reg_l2']\n",
    "        self.feature2field = config['feature2field']\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        self.X = tf.placeholder('float32', [self.batch_size, self.p])\n",
    "        self.y = tf.placeholder('int64', [None,])\n",
    "        self.keep_prob = tf.placeholder('float32')\n",
    "\n",
    "    def inference(self):\n",
    "        \"\"\"\n",
    "        forward propagation\n",
    "        :return: labels for each sample\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('linear_layer'):\n",
    "            b = tf.get_variable('bias', shape=[2],\n",
    "                                initializer=tf.zeros_initializer())\n",
    "            w1 = tf.get_variable('w1', shape=[self.p, 2],\n",
    "                                 initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n",
    "            # shape of [None, 2]\n",
    "            self.linear_terms = tf.add(tf.matmul(self.X, w1), b)\n",
    "\n",
    "        with tf.variable_scope('field_aware_interaction_layer'):\n",
    "            v = tf.get_variable('v', shape=[self.p, self.f, self.k], dtype='float32',\n",
    "                                initializer=tf.truncated_normal_initializer(mean=0, stddev=0.01))\n",
    "            # shape of [None, 1]\n",
    "            self.field_aware_interaction_terms = tf.constant(0, dtype='float32')\n",
    "            # build dict to find f, key of feature,value of field\n",
    "            for i in range(self.p):\n",
    "                for j in range(i+1,self.p):\n",
    "                    self.field_aware_interaction_terms += tf.multiply(\n",
    "                        tf.reduce_sum(tf.multiply(v[i,self.feature2field[i]], v[j,self.feature2field[j]])),\n",
    "                        tf.multiply(self.X[:,i], self.X[:,j])\n",
    "                    )\n",
    "        # shape of [None, 2]\n",
    "        self.y_out = tf.add(self.linear_terms, self.field_aware_interaction_terms)\n",
    "        self.y_out_prob = tf.nn.softmax(self.y_out)\n",
    "\n",
    "    def add_loss(self):\n",
    "            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=self.y_out)\n",
    "            mean_loss = tf.reduce_mean(cross_entropy)\n",
    "            self.loss = mean_loss\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "    def add_accuracy(self):\n",
    "        # accuracy\n",
    "        self.correct_prediction = tf.equal(tf.cast(tf.argmax(model.y_out,1), tf.int64), model.y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        # add summary to accuracy\n",
    "        tf.summary.scalar('accuracy', self.accuracy)\n",
    "\n",
    "    def train(self):\n",
    "        # Applies exponential decay to learning rate\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        # define optimizer\n",
    "        optimizer = tf.train.AdagradDAOptimizer(self.lr, global_step=self.global_step)\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"build graph for model\"\"\"\n",
    "        self.add_placeholders()\n",
    "        self.inference()\n",
    "        self.add_loss()\n",
    "        self.add_accuracy()\n",
    "        self.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
