{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_num is 1000, sequence_length is 5\n",
    "# create an embedding layer with 1000 row, and 5 width\n",
    "embedding_layer = layers.Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0221931 , -0.00781777,  0.0019397 , -0.03057138,  0.01572508],\n",
       "       [ 0.00952963, -0.0321022 , -0.01398076, -0.02946041,  0.0023345 ],\n",
       "       [ 0.00171735,  0.0263508 , -0.03899754, -0.04970043,  0.03538061]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5)\n",
      "[[[-0.01578252  0.0023705  -0.03343515  0.03090265  0.03187299]\n",
      "  [ 0.0221931  -0.00781777  0.0019397  -0.03057138  0.01572508]\n",
      "  [ 0.00952963 -0.0321022  -0.01398076 -0.02946041  0.0023345 ]]\n",
      "\n",
      " [[ 0.00171735  0.0263508  -0.03899754 -0.04970043  0.03538061]\n",
      "  [-0.00239437 -0.02851334 -0.01150944 -0.01987631  0.04672113]\n",
      "  [-0.02900649  0.03507973  0.00384105  0.00384574  0.03763301]]]\n"
     ]
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[0, 1, 2], [3, 4, 5]]))\n",
    "print(result.shape)\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "tfds.disable_progress_bar()\n",
    "(train_data, test_data), info = tfds.load(\n",
    "    'imdb_reviews/subwords8k',\n",
    "    data_dir='~/work/temp/tfds',\n",
    "    split=(tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "    with_info=True, as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the_',\n",
       " ', ',\n",
       " '. ',\n",
       " 'a_',\n",
       " 'and_',\n",
       " 'of_',\n",
       " 'to_',\n",
       " 's_',\n",
       " 'is_',\n",
       " 'br',\n",
       " 'in_',\n",
       " 'I_',\n",
       " 'that_',\n",
       " 'this_',\n",
       " 'it_',\n",
       " ' /><',\n",
       " ' />',\n",
       " 'was_',\n",
       " 'The_',\n",
       " 'as_']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = info.features['text'].encoder\n",
    "encoder.subwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_data.shuffle(1000).padded_batch(10)\n",
    "test_batches = test_data.shuffle(1000).padded_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  69,   57,  116, ...,    0,    0,    0],\n",
       "       [7448, 7961, 7228, ...,    0,    0,    0],\n",
       "       [  62,    9,    4, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [6998, 3149, 7961, ...,    0,    0,    0],\n",
       "       [ 274,    4, 3073, ...,    0,    0,    0],\n",
       "       [7514,   60, 1364, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch, train_labels = next(iter(train_batches))\n",
    "train_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          130960    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 131,249\n",
      "Trainable params: 131,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(encoder.vocab_size, embedding_dim),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5129 - accuracy: 0.6923 - val_loss: 0.3696 - val_accuracy: 0.8600\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2893 - accuracy: 0.8797 - val_loss: 0.3133 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2326 - accuracy: 0.9080 - val_loss: 0.4329 - val_accuracy: 0.8550\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2028 - accuracy: 0.9229 - val_loss: 0.3923 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1799 - accuracy: 0.9323 - val_loss: 0.3414 - val_accuracy: 0.8650\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1598 - accuracy: 0.9398 - val_loss: 0.3314 - val_accuracy: 0.8800\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1448 - accuracy: 0.9467 - val_loss: 0.3386 - val_accuracy: 0.8850\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1345 - accuracy: 0.9522 - val_loss: 0.5323 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1217 - accuracy: 0.9570 - val_loss: 0.3466 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1120 - accuracy: 0.9610 - val_loss: 0.4538 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=10,\n",
    "    validation_data=test_batches, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8185, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
